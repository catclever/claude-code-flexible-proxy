# å¯¹è¯å†å²å’Œå¢å¼ºçš„å¤šæ¨¡å‹åˆ‡æ¢åŠŸèƒ½

è¿™ä¸ªé¡¹ç›®ç°åœ¨æ”¯æŒå¼ºå¤§çš„æ–°åŠŸèƒ½ï¼š

## 1. å¢å¼ºçš„å®æ—¶æ¨¡å‹åˆ‡æ¢

### ğŸš€ æ ¸å¿ƒç‰¹æ€§

- **è·¨æä¾›å•†é…ç½®**: å¤§å°æ¨¡å‹å¯ä»¥æ¥è‡ªä¸åŒçš„æä¾›å•†
- **æ™ºèƒ½æ¨¡å‹æ˜ å°„**: è‡ªåŠ¨è¯†åˆ«æ¨¡å‹æ‰€å±æä¾›å•†å¹¶æ·»åŠ æ­£ç¡®å‰ç¼€
- **é¢„è®¾é…ç½®**: 7ç§é¢„è®¾ç»„åˆï¼Œä¸€é”®åˆ‡æ¢
- **60+æ¨¡å‹æ”¯æŒ**: OpenAI (30+) + Gemini (15+) + Anthropic (13+)

### ğŸ“Š æ”¯æŒçš„æ¨¡å‹

#### OpenAI (30+ æ¨¡å‹)
- **Oç³»åˆ—**: o3-mini, o1, o1-mini, o1-pro, o1-preview
- **GPT-4oç³»åˆ—**: gpt-4o, gpt-4o-mini, gpt-4o-audio-preview ç­‰
- **GPT-4 Turbo**: gpt-4-turbo, gpt-4-turbo-2024-04-09 ç­‰
- **GPT-3.5ç³»åˆ—**: gpt-3.5-turbo, gpt-3.5-turbo-16k ç­‰

#### Gemini (15+ æ¨¡å‹)  
- **Gemini 2.0ç³»åˆ—**: gemini-2.0-flash-exp, gemini-2.0-flash-thinking-exp
- **Gemini 1.5ç³»åˆ—**: gemini-1.5-pro, gemini-1.5-flash, gemini-1.5-flash-8b
- **å®éªŒç‰ˆæœ¬**: gemini-exp-1114, gemini-exp-1121

#### Anthropic (13+ æ¨¡å‹)
- **Claude 3.5ç³»åˆ—**: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
- **Claude 3ç³»åˆ—**: claude-3-opus-20240229, claude-3-sonnet-20240229
- **ç»å…¸ç‰ˆæœ¬**: claude-2.1, claude-instant-1.2

### ğŸ›ï¸ é¢„è®¾é…ç½®

#### æŸ¥çœ‹æ‰€æœ‰æ¨¡å‹å’Œé¢„è®¾
```bash
GET /models
```

#### 7ç§é¢„è®¾é…ç½®
1. **openai_only**: GPT-4o + GPT-4o Mini (çº¯OpenAI)
2. **gemini_only**: Gemini 1.5 Pro + Flash (çº¯Gemini)  
3. **anthropic_only**: Claude 3.5 Sonnet + Haiku (çº¯Anthropic)
4. **mixed_premium**: GPT-4o + Gemini Flash (æ··åˆé«˜ç«¯)
5. **mixed_cost_effective**: Gemini Pro + GPT-4o Mini (æ··åˆç»æµ)
6. **reasoning_focused**: O1 + GPT-4o Mini (æ¨ç†ä¼˜åŒ–)
7. **speed_focused**: Claude Haiku + Gemini Flash (é€Ÿåº¦ä¼˜åŒ–)

### API æ¥å£

#### æŸ¥çœ‹å½“å‰é…ç½®
```bash
GET /config
```

#### ä½¿ç”¨é¢„è®¾å¿«é€Ÿåˆ‡æ¢
```bash
POST /switch_model
```

```json
{
  "preset": "mixed_premium"  // ä½¿ç”¨é¢„è®¾é…ç½®
}
```

#### è‡ªå®šä¹‰è·¨æä¾›å•†é…ç½®
```json
{
  "big_model": "claude-3-5-sonnet-20241022",   // Anthropic
  "small_model": "gpt-4o-mini",                // OpenAI  
  "preserve_conversation": true
}
```

#### ä¼ ç»Ÿé…ç½®æ¨¡å¼
```json
{
  "preferred_provider": "openai",
  "big_model": "gpt-4o", 
  "small_model": "gpt-4o-mini",
  "preserve_conversation": true
}
```

## 2. å¯¹è¯å†å²ç®¡ç†

ç³»ç»Ÿä¼šè‡ªåŠ¨è®°å½•æ‰€æœ‰å¯¹è¯å†å²ï¼ŒåŒ…æ‹¬ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹å›å¤ï¼Œä»¥åŠä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯ã€‚

### API æ¥å£

#### æŸ¥çœ‹å¯¹è¯å†å²
```bash
GET /conversation?limit=10  # limitå‚æ•°å¯é€‰
```

è¿”å›ç¤ºä¾‹ï¼š
```json
{
  "messages": [
    {
      "timestamp": "2024-01-01T12:00:00",
      "role": "user",
      "content": "ä½ å¥½",
      "model_used": "openai/gpt-4o-mini"
    },
    {
      "timestamp": "2024-01-01T12:00:01",
      "role": "assistant", 
      "content": "ä½ å¥½ï¼æˆ‘æ˜¯åŠ©æ‰‹...",
      "model_used": "openai/gpt-4o-mini"
    }
  ],
  "total_count": 2
}
```

#### æ¸…ç©ºå¯¹è¯å†å²
```bash
DELETE /conversation
```

#### ä½¿ç”¨å†å²å¯¹è¯ç»§ç»­èŠå¤©
```bash
POST /conversation/continue
```

è¿™ä¸ªæ¥å£ä¼šå°†å†å²å¯¹è¯ä¸æ–°æ¶ˆæ¯åˆå¹¶ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿçœ‹åˆ°å®Œæ•´çš„ä¸Šä¸‹æ–‡ã€‚

## ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šåœ¨å¯¹è¯ä¸­åˆ‡æ¢æ¨¡å‹
```bash
# 1. ç”¨Claude Haikuå¼€å§‹å¯¹è¯
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -d '{
    "model": "haiku",
    "max_tokens": 100,
    "messages": [{"role": "user", "content": "ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}]
  }'

# 2. åˆ‡æ¢åˆ°æ›´å¼ºå¤§çš„æ¨¡å‹
curl -X POST http://localhost:8082/switch_model \
  -H "Content-Type: application/json" \
  -d '{
    "preferred_provider": "openai",
    "big_model": "gpt-4o",
    "preserve_conversation": true
  }'

# 3. ç»§ç»­å¯¹è¯ï¼Œç°åœ¨ä½¿ç”¨æ–°æ¨¡å‹ä½†ä¿æŒå†å²
curl -X POST http://localhost:8082/v1/messages \
  -H "Content-Type: application/json" \
  -d '{
    "model": "sonnet",
    "max_tokens": 200,
    "messages": [{"role": "user", "content": "è¯¦ç»†è§£é‡Šä¸€ä¸‹ä½ çš„èƒ½åŠ›"}]
  }'
```

### åœºæ™¯2ï¼šæŸ¥çœ‹å’Œç®¡ç†å¯¹è¯å†å²
```bash
# æŸ¥çœ‹å¯¹è¯å†å²
curl http://localhost:8082/conversation

# æ¸…ç©ºå¯¹è¯é‡æ–°å¼€å§‹
curl -X DELETE http://localhost:8082/conversation

# ä½¿ç”¨å†å²ç»§ç»­å¯¹è¯
curl -X POST http://localhost:8082/conversation/continue \
  -H "Content-Type: application/json" \
  -d '{
    "model": "haiku",
    "max_tokens": 100,
    "messages": [{"role": "user", "content": "æ€»ç»“ä¸€ä¸‹æˆ‘ä»¬åˆšæ‰çš„å¯¹è¯"}]
  }'
```

## ç‰¹æ€§

1. **æ— ç¼åˆ‡æ¢**: æ¨¡å‹åˆ‡æ¢ä¸ä¼šä¸­æ–­å½“å‰ä¼šè¯
2. **å†å²ä¿æŒ**: åˆ‡æ¢æ¨¡å‹æ—¶å¯ä»¥é€‰æ‹©ä¿æŒå¯¹è¯å†å²
3. **çµæ´»é…ç½®**: æ”¯æŒOpenAIã€Google Geminiã€Anthropicä¸‰ç§æä¾›å•†
4. **è‡ªåŠ¨è®°å½•**: æ‰€æœ‰å¯¹è¯éƒ½ä¼šè‡ªåŠ¨è®°å½•ï¼Œæ— éœ€é¢å¤–é…ç½®
5. **å…¼å®¹æ€§**: ä¿æŒä¸ç°æœ‰APIçš„å®Œå…¨å…¼å®¹

## æµ‹è¯•

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š
```bash
python conversation_test.py
```

è¿™ä¼šæµ‹è¯•æ‰€æœ‰æ–°åŠŸèƒ½çš„å®Œæ•´æµç¨‹ã€‚